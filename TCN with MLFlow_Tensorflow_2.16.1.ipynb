{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson.binary import Binary\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation, Layer, Conv1D, Input, Dense, SpatialDropout1D, BatchNormalization, Lambda, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,  ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MongoDatabase:\n",
    "    def __init__(self):\n",
    "        CONNECTION_STRING = \"mongodb://netdb:netdb3230!@10.255.93.173:27017/\"\n",
    "        self.client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "    def _fetch_data(self, collection_name, limit=None):\n",
    "        \"\"\"Private method to fetch data from a specified collection in MongoDB.\"\"\"\n",
    "        try:\n",
    "            collection = self.client[\"TestAPI\"][collection_name]\n",
    "            cursor = collection.find({}).limit(limit) if limit else collection.find({})\n",
    "            return pd.DataFrame(list(cursor))\n",
    "        except Exception as e:\n",
    "            print(f\"Error while fetching data from {collection_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_environment(self, limit=None):\n",
    "        \"\"\"Public method to fetch environment data from the 'GH2' collection.\"\"\"\n",
    "        return self._fetch_data(\"GH2\", limit)\n",
    "\n",
    "    def get_growth(self, limit=None):\n",
    "        \"\"\"Public method to fetch growth data from the 'hydroponics_length1' collection.\"\"\"\n",
    "        return self._fetch_data(\"hydroponics_length1\", limit)\n",
    "\n",
    "    def save_model(self, model, model_name, model_type):\n",
    "        \"\"\"Method to save a model to MongoDB. It saves the model's HDF5 file.\"\"\"\n",
    "        model_file = f\"{model_name}.h5\"\n",
    "        model.save(model_file)\n",
    "\n",
    "        # Read and store the HDF5 file data\n",
    "        with open(model_file, 'rb') as file:\n",
    "            model_data = file.read()\n",
    "\n",
    "        db = self.client[\"Things_to_refer\"]\n",
    "        collection = db[\"Previous_model_features\"]\n",
    "\n",
    "        # Create a document with model information\n",
    "        model_document = {\n",
    "            \"name\": model_name,\n",
    "            \"type\": model_type,\n",
    "            \"model_data\": Binary(model_data)\n",
    "        }\n",
    "\n",
    "        # Check if a model with the same name exists and update it, else insert a new document\n",
    "        existing_document = collection.find_one({\"name\": model_name})\n",
    "        if existing_document:\n",
    "            collection.update_one({\"_id\": existing_document[\"_id\"]}, {\"$set\": model_document})\n",
    "            print(f\"Existing model '{model_name}' updated in MongoDB.\")\n",
    "        else:\n",
    "            collection.insert_one(model_document)\n",
    "            print(f\"New model '{model_name}' inserted into MongoDB.\")\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        \"\"\"Method to load a model from MongoDB.\"\"\"\n",
    "        try:\n",
    "            db = self.client[\"Things_to_refer\"]\n",
    "            collection = db[\"Previous_model_features\"]\n",
    "            model_document = collection.find_one({\"name\": model_name})\n",
    "            \n",
    "            if model_document:\n",
    "                model_data = model_document[\"model_data\"]\n",
    "                with open(f\"{model_name}.h5\", 'wb') as file:\n",
    "                    file.write(model_data)\n",
    "                model = tf.keras.models.load_model(f\"{model_name}.h5\")\n",
    "                print(f\"Model '{model_name}' loaded from MongoDB.\")\n",
    "                return model\n",
    "            else:\n",
    "                print(f\"No model found with the name '{model_name}'.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error while loading model '{model_name}': {e}\")\n",
    "            return None\n",
    "\n",
    "# Create an instance of the MongoDatabase class\n",
    "db = MongoDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Growth Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sample_num</th>\n",
       "      <th>plant_height              (㎝)</th>\n",
       "      <th>plant_diameter           (㎜)</th>\n",
       "      <th>leaflet          (cm)</th>\n",
       "      <th>leaf_width         (cm)</th>\n",
       "      <th>last_flower_point         (th)</th>\n",
       "      <th>growing_point_to_flower_point        (㎝)</th>\n",
       "      <th>growth length   (cm)</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64a292929dca7929d1c1ed37</td>\n",
       "      <td>221228</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64a292929dca7929d1c1ed38</td>\n",
       "      <td>221228</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64a292929dca7929d1c1ed39</td>\n",
       "      <td>221228</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64a292929dca7929d1c1ed3a</td>\n",
       "      <td>221228</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64a292929dca7929d1c1ed3b</td>\n",
       "      <td>221228</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>64a292929dca7929d1c1ee6a</td>\n",
       "      <td>230329</td>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>11.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>64a292929dca7929d1c1ee6b</td>\n",
       "      <td>230329</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>64a292929dca7929d1c1ee6c</td>\n",
       "      <td>230329</td>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>6.8</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>64a292929dca7929d1c1ee6d</td>\n",
       "      <td>230329</td>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>64a292929dca7929d1c1ee6e</td>\n",
       "      <td>230329</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>16.7</td>\n",
       "      <td>20.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          _id    date  sample_num  \\\n",
       "0    64a292929dca7929d1c1ed37  221228           1   \n",
       "1    64a292929dca7929d1c1ed38  221228           2   \n",
       "2    64a292929dca7929d1c1ed39  221228           3   \n",
       "3    64a292929dca7929d1c1ed3a  221228           4   \n",
       "4    64a292929dca7929d1c1ed3b  221228           5   \n",
       "..                        ...     ...         ...   \n",
       "307  64a292929dca7929d1c1ee6a  230329          20   \n",
       "308  64a292929dca7929d1c1ee6b  230329          21   \n",
       "309  64a292929dca7929d1c1ee6c  230329          22   \n",
       "310  64a292929dca7929d1c1ee6d  230329          23   \n",
       "311  64a292929dca7929d1c1ee6e  230329          24   \n",
       "\n",
       "    plant_height              (㎝) plant_diameter           (㎜)  \\\n",
       "0                            None                         None   \n",
       "1                            None                         None   \n",
       "2                            None                         None   \n",
       "3                            None                         None   \n",
       "4                            None                         None   \n",
       "..                            ...                          ...   \n",
       "307                          None                         None   \n",
       "308                          None                         None   \n",
       "309                          None                         None   \n",
       "310                          None                         None   \n",
       "311                          None                         None   \n",
       "\n",
       "     leaflet          (cm)  leaf_width         (cm)  \\\n",
       "0                      NaN                      NaN   \n",
       "1                      NaN                      NaN   \n",
       "2                     33.0                      NaN   \n",
       "3                      NaN                      NaN   \n",
       "4                      NaN                      NaN   \n",
       "..                     ...                      ...   \n",
       "307                    NaN                      NaN   \n",
       "308                    NaN                      NaN   \n",
       "309                    NaN                      NaN   \n",
       "310                    NaN                      NaN   \n",
       "311                    NaN                      NaN   \n",
       "\n",
       "     last_flower_point         (th)  growing_point_to_flower_point        (㎝)  \\\n",
       "0                                 3                                      11.8   \n",
       "1                                 3                                      12.6   \n",
       "2                                 3                                      13.1   \n",
       "3                                 3                                      11.7   \n",
       "4                                 3                                      15.8   \n",
       "..                              ...                                       ...   \n",
       "307                              11                                      11.4   \n",
       "308                              12                                      13.8   \n",
       "309                              12                                       6.8   \n",
       "310                              12                                       9.0   \n",
       "311                              12                                      16.7   \n",
       "\n",
       "     growth length   (cm) note  \n",
       "0                     0.0  NaN  \n",
       "1                     0.0  NaN  \n",
       "2                     0.0  NaN  \n",
       "3                     0.0  NaN  \n",
       "4                     0.0  NaN  \n",
       "..                    ...  ...  \n",
       "307                  22.5  NaN  \n",
       "308                  21.8  NaN  \n",
       "309                  19.0  NaN  \n",
       "310                  20.8  NaN  \n",
       "311                  20.1  NaN  \n",
       "\n",
       "[312 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch growth data using the 'get_growth' method from the 'db' object\n",
    "growth_data_1 = db.get_growth()\n",
    "print(\"Original Growth Data:\")\n",
    "growth_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Growth Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>growth length   (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     growth length   (cm)\n",
       "0                     0.0\n",
       "1                     0.0\n",
       "2                     0.0\n",
       "3                     0.0\n",
       "4                     0.0\n",
       "..                    ...\n",
       "307                  22.5\n",
       "308                  21.8\n",
       "309                  19.0\n",
       "310                  20.8\n",
       "311                  20.1\n",
       "\n",
       "[312 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "growth_data_2 = growth_data_1.drop(columns=['_id', 'date', 'sample_num', 'plant_height              (㎝)', 'plant_diameter           (㎜)', 'leaflet          (cm)', 'leaf_width         (cm)', 'last_flower_point         (th)', 'growing_point_to_flower_point        (㎝)', 'note'], errors='ignore')\n",
    "print(\"Processed Growth Data:\")\n",
    "growth_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Environment Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>inFacilityId</th>\n",
       "      <th>sensorNo</th>\n",
       "      <th>sensingAt</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64a6ab104d0a1349ef3e86fd</td>\n",
       "      <td>151373270</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-06 00:00:01</td>\n",
       "      <td>16.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64a6ab104d0a1349ef3e86fe</td>\n",
       "      <td>151373577</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-06 00:01:01</td>\n",
       "      <td>16.4</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64a6ab104d0a1349ef3e86ff</td>\n",
       "      <td>151373884</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-06 00:02:01</td>\n",
       "      <td>16.4</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64a6ab104d0a1349ef3e8700</td>\n",
       "      <td>151374204</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-06 00:03:01</td>\n",
       "      <td>16.4</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64a6ab104d0a1349ef3e8701</td>\n",
       "      <td>151374511</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-06 00:04:01</td>\n",
       "      <td>16.4</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31195</th>\n",
       "      <td>64a6ab2d4d0a1349ef3f00d8</td>\n",
       "      <td>161019918</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-27 16:45:27</td>\n",
       "      <td>17.4</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31196</th>\n",
       "      <td>64a6ab2d4d0a1349ef3f00d9</td>\n",
       "      <td>161020107</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-27 16:46:27</td>\n",
       "      <td>17.3</td>\n",
       "      <td>51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31197</th>\n",
       "      <td>64a6ab2d4d0a1349ef3f00da</td>\n",
       "      <td>161020289</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-27 16:47:27</td>\n",
       "      <td>17.3</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31198</th>\n",
       "      <td>64a6ab2d4d0a1349ef3f00db</td>\n",
       "      <td>161020467</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-27 16:48:27</td>\n",
       "      <td>17.2</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31199</th>\n",
       "      <td>64a6ab2d4d0a1349ef3f00dc</td>\n",
       "      <td>161020655</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-27 16:49:27</td>\n",
       "      <td>17.1</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id         id  inFacilityId  sensorNo  \\\n",
       "0      64a6ab104d0a1349ef3e86fd  151373270            34         1   \n",
       "1      64a6ab104d0a1349ef3e86fe  151373577            34         1   \n",
       "2      64a6ab104d0a1349ef3e86ff  151373884            34         1   \n",
       "3      64a6ab104d0a1349ef3e8700  151374204            34         1   \n",
       "4      64a6ab104d0a1349ef3e8701  151374511            34         1   \n",
       "...                         ...        ...           ...       ...   \n",
       "31195  64a6ab2d4d0a1349ef3f00d8  161019918            34         1   \n",
       "31196  64a6ab2d4d0a1349ef3f00d9  161020107            34         1   \n",
       "31197  64a6ab2d4d0a1349ef3f00da  161020289            34         1   \n",
       "31198  64a6ab2d4d0a1349ef3f00db  161020467            34         1   \n",
       "31199  64a6ab2d4d0a1349ef3f00dc  161020655            34         1   \n",
       "\n",
       "                 sensingAt  temp  humidity  \n",
       "0      2023-01-06 00:00:01  16.3      50.0  \n",
       "1      2023-01-06 00:01:01  16.4      50.0  \n",
       "2      2023-01-06 00:02:01  16.4      50.0  \n",
       "3      2023-01-06 00:03:01  16.4      49.6  \n",
       "4      2023-01-06 00:04:01  16.4      49.6  \n",
       "...                    ...   ...       ...  \n",
       "31195  2023-01-27 16:45:27  17.4      51.7  \n",
       "31196  2023-01-27 16:46:27  17.3      51.5  \n",
       "31197  2023-01-27 16:47:27  17.3      51.7  \n",
       "31198  2023-01-27 16:48:27  17.2      51.4  \n",
       "31199  2023-01-27 16:49:27  17.1      51.3  \n",
       "\n",
       "[31200 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch environment data using the 'get_environment' method from the 'db' object.\n",
    "environment_data_1 = db.get_environment(limit = 31200)\n",
    "print(\"Original Environment Data:\")\n",
    "environment_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Environment Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.3</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.4</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.4</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.4</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.4</td>\n",
       "      <td>49.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31195</th>\n",
       "      <td>17.4</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31196</th>\n",
       "      <td>17.3</td>\n",
       "      <td>51.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31197</th>\n",
       "      <td>17.3</td>\n",
       "      <td>51.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31198</th>\n",
       "      <td>17.2</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31199</th>\n",
       "      <td>17.1</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp  humidity\n",
       "0      16.3      50.0\n",
       "1      16.4      50.0\n",
       "2      16.4      50.0\n",
       "3      16.4      49.6\n",
       "4      16.4      49.6\n",
       "...     ...       ...\n",
       "31195  17.4      51.7\n",
       "31196  17.3      51.5\n",
       "31197  17.3      51.7\n",
       "31198  17.2      51.4\n",
       "31199  17.1      51.3\n",
       "\n",
       "[31200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify the 'environment_data_1' DataFrame to drop specified columns.\n",
    "# environment_data_2 = environment_data_1.drop(columns=['_id', 'id', 'inFacilityId', 'sensorNo', 'sensingAt'], errors='ignore')\n",
    "environment_data_2 = environment_data_1.drop(columns=['_id', 'id', 'inFacilityId', 'sensorNo', 'sensingAt', 'co2'], errors='ignore')\n",
    "print(\"Processed Environment Data:\")\n",
    "environment_data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Environment Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.264</td>\n",
       "      <td>50.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.175</td>\n",
       "      <td>48.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.074</td>\n",
       "      <td>46.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.946</td>\n",
       "      <td>46.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.877</td>\n",
       "      <td>49.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>16.834</td>\n",
       "      <td>47.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>19.122</td>\n",
       "      <td>49.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>23.893</td>\n",
       "      <td>43.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>24.944</td>\n",
       "      <td>42.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>22.223</td>\n",
       "      <td>47.246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp  humidity\n",
       "0    16.264    50.510\n",
       "1    16.175    48.458\n",
       "2    16.074    46.633\n",
       "3    15.946    46.642\n",
       "4    15.877    49.113\n",
       "..      ...       ...\n",
       "307  16.834    47.135\n",
       "308  19.122    49.298\n",
       "309  23.893    43.809\n",
       "310  24.944    42.963\n",
       "311  22.223    47.246\n",
       "\n",
       "[312 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment_averaged = environment_data_2.groupby(environment_data_2.index // 100).mean(numeric_only=True).reset_index(drop=True)\n",
    "print(\"Averaged Environment Data:\")\n",
    "environment_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>growth length   (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.264</td>\n",
       "      <td>50.510</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.175</td>\n",
       "      <td>48.458</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.074</td>\n",
       "      <td>46.633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.946</td>\n",
       "      <td>46.642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.877</td>\n",
       "      <td>49.113</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>16.834</td>\n",
       "      <td>47.135</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>19.122</td>\n",
       "      <td>49.298</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>23.893</td>\n",
       "      <td>43.809</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>24.944</td>\n",
       "      <td>42.963</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>22.223</td>\n",
       "      <td>47.246</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temp  humidity  growth length   (cm)\n",
       "0    16.264    50.510                   0.0\n",
       "1    16.175    48.458                   0.0\n",
       "2    16.074    46.633                   0.0\n",
       "3    15.946    46.642                   0.0\n",
       "4    15.877    49.113                   0.0\n",
       "..      ...       ...                   ...\n",
       "307  16.834    47.135                  22.5\n",
       "308  19.122    49.298                  21.8\n",
       "309  23.893    43.809                  19.0\n",
       "310  24.944    42.963                  20.8\n",
       "311  22.223    47.246                  20.1\n",
       "\n",
       "[312 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the 'environment_averaged' DataFrame and 'growth_data_2' DataFrame based on their indices.\n",
    "training_data = pd.merge(environment_averaged, growth_data_2, left_index=True, right_index=True)\n",
    "print(\"Merged Training Data:\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training Data:\n",
      "[[0.3154488  0.32528391 0.        ]\n",
      " [0.31094817 0.29218286 0.        ]\n",
      " [0.30584071 0.26274358 0.        ]\n",
      " [0.29936789 0.26288876 0.        ]\n",
      " [0.29587863 0.30274874 0.        ]\n",
      " [0.29269279 0.41063363 0.        ]\n",
      " [0.47347661 0.43789521 0.        ]\n",
      " [0.63731985 0.43660472 0.        ]\n",
      " [0.78948167 0.38575945 0.        ]\n",
      " [0.61522124 0.49524132 0.        ]\n",
      " [0.34498104 0.58368822 0.        ]\n",
      " [0.31130215 0.49667699 0.        ]\n",
      " [0.31115044 0.50261324 0.        ]\n",
      " [0.30629583 0.48173958 0.        ]\n",
      " [0.31160556 0.4685282  0.        ]\n",
      " [0.31438685 0.42615176 0.        ]\n",
      " [0.31509482 0.40756872 0.        ]\n",
      " [0.3117067  0.43165247 0.        ]\n",
      " [0.31145386 0.48486902 0.        ]\n",
      " [0.28591656 0.53348819 0.        ]\n",
      " [0.41228824 0.5033714  0.        ]\n",
      " [0.64510746 0.38385598 0.        ]\n",
      " [0.74250316 0.33976965 0.        ]\n",
      " [0.63489254 0.40522971 0.        ]\n",
      " [0.40353982 0.51764744 0.05508475]\n",
      " [0.3216182  0.41456962 0.21468927]\n",
      " [0.31676359 0.31292747 0.21186441]\n",
      " [0.31155499 0.25480707 0.17372881]\n",
      " [0.30477876 0.22530326 0.18220339]\n",
      " [0.30351454 0.21230159 0.15536723]\n",
      " [0.30083439 0.20530068 0.17231638]\n",
      " [0.29815424 0.21725384 0.24152542]\n",
      " [0.29370417 0.23799845 0.22881356]\n",
      " [0.28905183 0.29213447 0.22033898]\n",
      " [0.33916561 0.40642341 0.26977401]\n",
      " [0.63888748 0.36883791 0.23022599]\n",
      " [0.9169153  0.30337786 0.14124294]\n",
      " [0.87504425 0.36459543 0.14830508]\n",
      " [0.61689001 0.49153117 0.20480226]\n",
      " [0.33456384 0.55712027 0.10169492]\n",
      " [0.31833123 0.40761711 0.16949153]\n",
      " [0.31646018 0.36414376 0.12711864]\n",
      " [0.31484197 0.35112595 0.18644068]\n",
      " [0.31868521 0.3536908  0.23305085]\n",
      " [0.31499368 0.35156149 0.2019774 ]\n",
      " [0.31504425 0.36583753 0.1539548 ]\n",
      " [0.30513274 0.48467544 0.21610169]\n",
      " [0.30457649 0.5699929  0.15960452]\n",
      " [0.26988622 0.67640986 0.17937853]\n",
      " [0.31458913 0.72467415 0.15677966]\n",
      " [0.34235145 0.71664086 0.17231638]\n",
      " [0.43246523 0.68147503 0.16949153]\n",
      " [0.38938053 0.68668538 0.16242938]\n",
      " [0.32869785 0.64277649 0.17655367]\n",
      " [0.29724399 0.5048716  0.18644068]\n",
      " [0.31292035 0.36296619 0.17655367]\n",
      " [0.3079646  0.28214931 0.16666667]\n",
      " [0.2980531  0.2308685  0.1440678 ]\n",
      " [0.29087231 0.19884824 0.1299435 ]\n",
      " [0.28672566 0.17469996 0.15536723]\n",
      " [0.28131479 0.1651826  0.1779661 ]\n",
      " [0.27666245 0.17310298 0.20056497]\n",
      " [0.27939317 0.22678733 0.17231638]\n",
      " [0.42993679 0.33873726 0.15819209]\n",
      " [0.78300885 0.26584075 0.14689266]\n",
      " [0.948622   0.22762615 0.21045198]\n",
      " [0.86553729 0.326526   0.17514124]\n",
      " [0.57931732 0.47412569 0.2019774 ]\n",
      " [0.32591656 0.50766228 0.17514124]\n",
      " [0.31742099 0.38743709 0.16949153]\n",
      " [0.3087737  0.30723319 0.14971751]\n",
      " [0.3063464  0.27479352 0.16949153]\n",
      " [0.30498104 0.26779262 0.24858757]\n",
      " [0.29957016 0.2388534  0.26836158]\n",
      " [0.2959292  0.23190089 0.24858757]\n",
      " [0.29324905 0.24217641 0.24152542]\n",
      " [0.28869785 0.27429346 0.26129944]\n",
      " [0.30902655 0.40563298 0.21892655]\n",
      " [0.58958281 0.39551878 0.23305085]\n",
      " [0.90907712 0.29347335 0.23305085]\n",
      " [0.93785082 0.35669119 0.26694915]\n",
      " [0.75565107 0.53719835 0.25423729]\n",
      " [0.41911504 0.64264744 0.25706215]\n",
      " [0.32       0.52274487 0.26836158]\n",
      " [0.31656131 0.39416376 0.25282486]\n",
      " [0.3102402  0.33862434 0.27966102]\n",
      " [0.31201011 0.31104013 0.27259887]\n",
      " [0.30847029 0.27889082 0.22033898]\n",
      " [0.30654867 0.28095561 0.23587571]\n",
      " [0.30432364 0.29865144 0.29661017]\n",
      " [0.30184576 0.32288037 0.32485876]\n",
      " [0.30017699 0.43124919 0.25423729]\n",
      " [0.49329962 0.48659504 0.19915254]\n",
      " [0.95302149 0.29550587 0.26836158]\n",
      " [1.         0.26392115 0.30225989]\n",
      " [0.91195954 0.34851271 0.24717514]\n",
      " [0.63302149 0.61856369 0.19774011]\n",
      " [0.42447535 0.69586398 0.14124294]\n",
      " [0.36970923 0.76967996 0.19067797]\n",
      " [0.34811631 0.80649116 0.18079096]\n",
      " [0.32738306 0.84433475 0.16242938]\n",
      " [0.32738306 0.87470964 0.22881356]\n",
      " [0.32510746 0.89580914 0.14124294]\n",
      " [0.32126422 0.92250613 0.17655367]\n",
      " [0.32733249 0.96105949 0.15536723]\n",
      " [0.32738306 0.99498322 0.16949153]\n",
      " [0.34184576 1.         0.17231638]\n",
      " [0.37633375 0.97222222 0.12711864]\n",
      " [0.38599241 0.95696219 0.16242938]\n",
      " [0.46083439 0.90827849 0.09887006]\n",
      " [0.36485461 0.94744483 0.15536723]\n",
      " [0.30745891 0.95557491 0.14830508]\n",
      " [0.30786346 0.875984   0.15536723]\n",
      " [0.31018963 0.80752355 0.14124294]\n",
      " [0.30938053 0.77453542 0.12711864]\n",
      " [0.31266751 0.74498322 0.12711864]\n",
      " [0.31165613 0.74199897 0.12711864]\n",
      " [0.30831858 0.73835334 0.18361582]\n",
      " [0.30968394 0.72498064 0.21186441]\n",
      " [0.30948167 0.71320493 0.19774011]\n",
      " [0.282933   0.75219383 0.60451977]\n",
      " [0.27281922 0.80431346 0.55084746]\n",
      " [0.29254109 0.80802362 0.59180791]\n",
      " [0.33163085 0.80939476 1.        ]\n",
      " [0.28015171 0.83065557 0.56638418]\n",
      " [0.3026043  0.74214415 0.59039548]\n",
      " [0.30685209 0.65518131 0.51553672]\n",
      " [0.30396966 0.59099561 0.5960452 ]\n",
      " [0.30139064 0.57720351 0.36864407]\n",
      " [0.30295828 0.56992838 0.54096045]\n",
      " [0.30756005 0.53876307 0.50282486]\n",
      " [0.30973451 0.50517809 0.52542373]\n",
      " [0.3125158  0.47633566 0.43926554]\n",
      " [0.30978508 0.462721   0.43079096]\n",
      " [0.28905183 0.48228804 0.46610169]\n",
      " [0.26159292 0.54818364 0.43785311]\n",
      " [0.26584071 0.59473803 0.46610169]\n",
      " [0.29026549 0.60494903 0.49717514]\n",
      " [0.28010114 0.60481998 0.49435028]\n",
      " [0.25850822 0.59028584 0.5       ]\n",
      " [0.29972187 0.43662085 0.53954802]\n",
      " [0.2783818  0.32746161 0.45480226]\n",
      " [0.25517067 0.31884759 0.57344633]\n",
      " [0.24955752 0.30820106 0.48022599]\n",
      " [0.30118837 0.24893535 0.3079096 ]\n",
      " [0.29173198 0.2221093  0.26271186]\n",
      " [0.27989886 0.1903794  0.33898305]\n",
      " [0.27297092 0.17557104 0.24858757]\n",
      " [0.26184576 0.18608853 0.31355932]\n",
      " [0.29921618 0.30768486 0.29661017]\n",
      " [0.52333755 0.32249322 0.20903955]\n",
      " [0.8006574  0.23582075 0.29237288]\n",
      " [0.81067004 0.27605175 0.26977401]\n",
      " [0.6300885  0.35319073 0.25564972]\n",
      " [0.35868521 0.41119822 0.29943503]\n",
      " [0.30553729 0.25888824 0.25282486]\n",
      " [0.29603034 0.19552523 0.33050847]\n",
      " [0.26761062 0.17166731 0.3559322 ]\n",
      " [0.28202276 0.16724739 0.33333333]\n",
      " [0.28262958 0.16690863 0.30367232]\n",
      " [0.27737042 0.16042393 0.30367232]\n",
      " [0.27509482 0.15919796 0.31497175]\n",
      " [0.27590392 0.20013873 0.22457627]\n",
      " [0.27499368 0.29773197 0.20480226]\n",
      " [0.39018963 0.39614789 0.22175141]\n",
      " [0.59443742 0.34735127 0.2019774 ]\n",
      " [0.82002528 0.28332688 0.25423729]\n",
      " [0.74295828 0.33889857 0.31920904]\n",
      " [0.43651075 0.46360821 0.2980226 ]\n",
      " [0.43428571 0.27671312 0.2740113 ]\n",
      " [0.34887484 0.26338882 0.27542373]\n",
      " [0.34088496 0.21160795 0.23305085]\n",
      " [0.33436157 0.18139437 0.30367232]\n",
      " [0.33142857 0.18228158 0.2740113 ]\n",
      " [0.33147914 0.19978384 0.16949153]\n",
      " [0.33360303 0.22904568 0.25706215]\n",
      " [0.33759798 0.28916634 0.20338983]\n",
      " [0.31661188 0.34525423 0.19774011]\n",
      " [0.37233881 0.42107046 0.21045198]\n",
      " [0.58771176 0.41150471 0.21892655]\n",
      " [0.8476359  0.31037876 0.27118644]\n",
      " [0.69132743 0.39503484 0.04661017]\n",
      " [0.44343869 0.51998645 0.25423729]\n",
      " [0.37026549 0.40956898 0.26129944]\n",
      " [0.35337547 0.27359982 0.24576271]\n",
      " [0.3395196  0.22320622 0.26694915]\n",
      " [0.3289507  0.19552523 0.17655367]\n",
      " [0.32323641 0.17531294 0.41101695]\n",
      " [0.32353982 0.16290812 0.14124294]\n",
      " [0.32131479 0.15389082 0.16525424]\n",
      " [0.32005057 0.15703639 0.19774011]\n",
      " [0.32232617 0.20310685 0.18361582]\n",
      " [0.36096081 0.30710414 0.32344633]\n",
      " [0.51964602 0.52287392 0.31779661]\n",
      " [0.76085967 0.4593012  0.33898305]\n",
      " [0.9011378  0.3355433  0.30367232]\n",
      " [0.77026549 0.40855272 0.30084746]\n",
      " [0.43241466 0.55245838 0.22881356]\n",
      " [0.35094817 0.51006581 0.27966102]\n",
      " [0.35731985 0.42092528 0.42514124]\n",
      " [0.35666245 0.38246871 0.38418079]\n",
      " [0.35792668 0.35959479 0.39548023]\n",
      " [0.35448799 0.38742096 0.36016949]\n",
      " [0.35565107 0.3798232  0.39830508]\n",
      " [0.3523641  0.35449735 0.29661017]\n",
      " [0.34963338 0.32963931 0.24717514]\n",
      " [0.35347661 0.37948445 0.30367232]\n",
      " [0.41471555 0.42132856 0.26977401]\n",
      " [0.66376738 0.27601949 0.24011299]\n",
      " [0.79519595 0.27332559 0.25706215]\n",
      " [0.73744627 0.31333075 0.29943503]\n",
      " [0.48839444 0.38725965 0.30932203]\n",
      " [0.36647282 0.27785843 0.33050847]\n",
      " [0.34558786 0.17810363 0.26836158]\n",
      " [0.33152971 0.14553491 0.30367232]\n",
      " [0.32247788 0.11325655 0.26836158]\n",
      " [0.30988622 0.0949316  0.22740113]\n",
      " [0.29178255 0.08368822 0.26412429]\n",
      " [0.291378   0.08009098 0.25423729]\n",
      " [0.25931732 0.12149955 0.23305085]\n",
      " [0.28844501 0.14655117 0.18220339]\n",
      " [0.34882427 0.30597496 0.21186441]\n",
      " [0.65785082 0.27824558 0.18926554]\n",
      " [0.88733249 0.248032   0.25847458]\n",
      " [0.86280657 0.29169893 0.21186441]\n",
      " [0.6996713  0.35869144 0.2259887 ]\n",
      " [0.39646018 0.41840883 0.18361582]\n",
      " [0.35307206 0.25280681 0.21892655]\n",
      " [0.34518331 0.2044296  0.26129944]\n",
      " [0.34300885 0.21802813 0.24011299]\n",
      " [0.3417952  0.20851078 0.21892655]\n",
      " [0.33628319 0.17734546 0.25706215]\n",
      " [0.33441214 0.18587882 0.29661017]\n",
      " [0.34103666 0.23443348 0.28531073]\n",
      " [0.34058154 0.28337527 0.25706215]\n",
      " [0.34548673 0.37466125 0.24717514]\n",
      " [0.38022756 0.51021099 0.27118644]\n",
      " [0.42280657 0.5615402  0.21186441]\n",
      " [0.42078382 0.60714286 0.2259887 ]\n",
      " [0.40085967 0.65542328 0.25706215]\n",
      " [0.35686473 0.66173055 0.29661017]\n",
      " [0.34513274 0.52409988 0.32485876]\n",
      " [0.35039191 0.36869273 0.30649718]\n",
      " [0.34553729 0.3163634  0.33898305]\n",
      " [0.34538559 0.30016776 0.29096045]\n",
      " [0.34589128 0.294538   0.33898305]\n",
      " [0.34675095 0.28918248 0.27683616]\n",
      " [0.34305942 0.25585559 0.32485876]\n",
      " [0.33385588 0.24048264 0.35310734]\n",
      " [0.33461441 0.27871338 0.3220339 ]\n",
      " [0.43357775 0.43397535 0.31779661]\n",
      " [0.75175727 0.36498258 0.36158192]\n",
      " [0.96783818 0.31515357 0.28813559]\n",
      " [0.88217446 0.37917796 0.27542373]\n",
      " [0.49734513 0.5406988  0.14830508]\n",
      " [0.36328698 0.49378952 0.37146893]\n",
      " [0.35974716 0.37388695 0.37288136]\n",
      " [0.36045512 0.31928313 0.35734463]\n",
      " [0.35150442 0.26682475 0.35310734]\n",
      " [0.34831858 0.1976868  0.33757062]\n",
      " [0.33810367 0.12766163 0.31214689]\n",
      " [0.32657396 0.08294619 0.32627119]\n",
      " [0.31474083 0.07502581 0.32485876]\n",
      " [0.28515803 0.05310363 0.3220339 ]\n",
      " [0.29840708 0.13304943 0.32485876]\n",
      " [0.52510746 0.14422829 0.32485876]\n",
      " [0.63393173 0.15048716 0.28248588]\n",
      " [0.54543616 0.24245064 0.31779661]\n",
      " [0.49921618 0.24437024 0.31073446]\n",
      " [0.29228824 0.27300297 0.36723164]\n",
      " [0.18771176 0.15303588 0.29661017]\n",
      " [0.2837421  0.03326236 0.31355932]\n",
      " [0.26523388 0.         0.31920904]\n",
      " [0.19994943 0.01069493 0.29661017]\n",
      " [0.16460177 0.00956575 0.30367232]\n",
      " [0.12950695 0.01309846 0.32485876]\n",
      " [0.09694058 0.02542264 0.21468927]\n",
      " [0.0785335  0.05691057 0.30367232]\n",
      " [0.12005057 0.10770745 0.26129944]\n",
      " [0.33001264 0.1971706  0.28248588]\n",
      " [0.65335019 0.15100336 0.30367232]\n",
      " [0.68657396 0.21436637 0.31355932]\n",
      " [0.677067   0.25998516 0.29519774]\n",
      " [0.5040708  0.32404181 0.34745763]\n",
      " [0.34452592 0.25211318 0.24858757]\n",
      " [0.26139064 0.12854885 0.3079096 ]\n",
      " [0.23403287 0.09557685 0.30367232]\n",
      " [0.         0.23520777 0.30084746]\n",
      " [0.11863464 0.14629307 0.33898305]\n",
      " [0.2580531  0.06036263 0.28248588]\n",
      " [0.27661188 0.14072784 0.32485876]\n",
      " [0.1042225  0.37161247 0.35310734]\n",
      " [0.13744627 0.3917441  0.33898305]\n",
      " [0.33527181 0.32146083 0.29661017]\n",
      " [0.42174463 0.4590431  0.32485876]\n",
      " [0.40642225 0.57299329 0.3319209 ]\n",
      " [0.37051833 0.58055878 0.25706215]\n",
      " [0.32890013 0.55270035 0.28248588]\n",
      " [0.33785082 0.41258549 0.29661017]\n",
      " [0.33638432 0.35570719 0.29096045]\n",
      " [0.33663717 0.31571816 0.25141243]\n",
      " [0.3380531  0.28895664 0.3319209 ]\n",
      " [0.33926675 0.2507259  0.27824859]\n",
      " [0.33006321 0.19915473 0.31779661]\n",
      " [0.31959545 0.14943864 0.3319209 ]\n",
      " [0.30371681 0.13072655 0.27966102]\n",
      " [0.30639697 0.19100852 0.27683616]\n",
      " [0.34427307 0.2708414  0.31779661]\n",
      " [0.45997472 0.305733   0.3079096 ]\n",
      " [0.70123894 0.21718931 0.26836158]\n",
      " [0.75438685 0.20354239 0.29378531]\n",
      " [0.61678887 0.27263195 0.28389831]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the MinMaxScaler.\n",
    "scaler = MinMaxScaler()\n",
    "# 'data_normalized' will be a NumPy array where each feature (column) of the input data is normalized to the range [0, 1].\n",
    "data_normalized = scaler.fit_transform(training_data)\n",
    "print(\"Normalized Training Data:\")\n",
    "print(data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, look_back=1):\n",
    "    \"\"\"\n",
    "    Create dataset for time-series forecasting.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input time-series data (features), a 2D NumPy array where rows represent time steps and columns represent features.\n",
    "    - y: Output time-series data (target), a 1D or 2D NumPy array where rows represent time steps.\n",
    "    - look_back (default=1): Number of previous time steps to use as input variables to predict the next time step.\n",
    "    \n",
    "    Returns:\n",
    "    - dataX: 3D NumPy array of the input sequences, shape (num_samples, look_back, num_features).\n",
    "    - dataY: 1D or 2D NumPy array of the output sequences, shape (num_samples, num_output_features).\n",
    "    \"\"\"\n",
    "    \n",
    "    dataX, dataY = [], []  # Initialize empty lists to hold our transformed sequences.\n",
    "    \n",
    "    # For each possible sequence in the input data...\n",
    "    for i in range(len(X) - look_back):\n",
    "        # Extract a sequence of 'look_back' features from the input data.\n",
    "        sequence = X[i:(i + look_back), :]\n",
    "        dataX.append(sequence)\n",
    "        \n",
    "        # Extract the output for this sequence from the 'y' data.\n",
    "        output = y[i + look_back]\n",
    "        dataY.append(output)\n",
    "\n",
    "    # Convert the lists into NumPy arrays for compatibility with most ML frameworks.\n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)\n",
    "\n",
    "    # Log the shape of the created datasets for debugging\n",
    "    print(f\"Input sequence shape: {dataX.shape}\")\n",
    "    print(f\"Output sequence shape: {dataY.shape}\")\n",
    "\n",
    "    return dataX, dataY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape: (302, 10, 2)\n",
      "Output sequence shape: (302,)\n",
      "Training data shape: X_train=(241, 10, 2), Y_train=(241,)\n",
      "Validation data shape: X_val=(30, 10, 2), Y_val=(30,)\n",
      "Test data shape: X_test=(31, 10, 2), Y_test=(31,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming the last column of 'data_normalized' is the target variable that want to predict.\n",
    "# 'data_normalized' is a 2D array with rows as individual data records and columns as features.\n",
    "\n",
    "# Extract input features (every column except the last one).\n",
    "X_data = data_normalized[:, :-1]\n",
    "\n",
    "# Extract target variable (just the last column).\n",
    "y_data = data_normalized[:, -1]\n",
    "\n",
    "# Define the look-back period, which determines the number of past observations \n",
    "# each input sequence will contain when transforming the data.\n",
    "look_back = 10\n",
    "\n",
    "# Transform the data into sequences of input (X) and output (Y) using the 'create_dataset' function.\n",
    "X, Y = create_dataset(X_data, y_data, look_back)\n",
    "\n",
    "# Define the size of the training set as 80% of the total data.\n",
    "train_size = int(len(X) * 0.8)\n",
    "\n",
    "# Split the data based on order (important for time series data).\n",
    "# The first 80% is used for training.\n",
    "X_train, X_temp = X[:train_size], X[train_size:]\n",
    "Y_train, Y_temp = Y[:train_size], Y[train_size:]\n",
    "\n",
    "# The remaining 20% is further divided into validation and test sets, each taking 10%.\n",
    "# Split the remaining data into half for validation and testing.\n",
    "val_size = len(X_temp) // 2\n",
    "\n",
    "# Extract validation and test sets from the remaining data.\n",
    "X_val, X_test = X_temp[:val_size], X_temp[val_size:]\n",
    "Y_val, Y_test = Y_temp[:val_size], Y_temp[val_size:]\n",
    "\n",
    "# Print shapes to verify the splits\n",
    "print(f\"Training data shape: X_train={X_train.shape}, Y_train={Y_train.shape}\")\n",
    "print(f\"Validation data shape: X_val={X_val.shape}, Y_val={Y_val.shape}\")\n",
    "print(f\"Test data shape: X_test={X_test.shape}, Y_test={Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_power_of_two(num: int):\n",
    "    return num != 0 and ((num & (num - 1)) == 0)\n",
    "\n",
    "def adjust_dilations(dilations: list):\n",
    "    if all([is_power_of_two(i) for i in dilations]):\n",
    "        return dilations\n",
    "    else:\n",
    "        new_dilations = [2 ** i for i in dilations]\n",
    "        return new_dilations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, dilation_rate, nb_filters, kernel_size, padding, activation='relu',\n",
    "                 dropout_rate=0, kernel_initializer='he_normal', use_batch_norm=False,\n",
    "                 use_layer_norm=False, use_weight_norm=False, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.nb_filters = nb_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.activation = activation\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_weight_norm = use_weight_norm\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "\n",
    "        self.conv_layers = []\n",
    "        for k in range(2):\n",
    "            self.conv_layers.append(Conv1D(filters=self.nb_filters,\n",
    "                                           kernel_size=self.kernel_size,\n",
    "                                           dilation_rate=self.dilation_rate,\n",
    "                                           padding=self.padding,\n",
    "                                           kernel_initializer=self.kernel_initializer))\n",
    "            if self.use_batch_norm:\n",
    "                self.conv_layers.append(BatchNormalization())\n",
    "            if self.use_layer_norm:\n",
    "                self.conv_layers.append(LayerNormalization())\n",
    "            self.conv_layers.append(Activation(self.activation))\n",
    "            self.conv_layers.append(SpatialDropout1D(rate=self.dropout_rate))\n",
    "        \n",
    "        if self.nb_filters != self.kernel_size:\n",
    "            self.shape_match_conv = Conv1D(filters=self.nb_filters,\n",
    "                                           kernel_size=1,\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=self.kernel_initializer)\n",
    "        else:\n",
    "            self.shape_match_conv = Lambda(lambda x: x)\n",
    "        \n",
    "        self.final_activation = Activation(self.activation)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x, training=training)\n",
    "        \n",
    "        res_x = self.shape_match_conv(inputs)\n",
    "        x += res_x\n",
    "        return self.final_activation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(Layer):\n",
    "    def __init__(self, nb_filters=64, kernel_size=3, nb_stacks=1, dilations=(1, 2, 4, 8, 16, 32),\n",
    "                 padding='causal', use_skip_connections=True, dropout_rate=0.0,\n",
    "                 return_sequences=False, activation='relu', kernel_initializer='he_normal',\n",
    "                 use_batch_norm=False, use_layer_norm=False, use_weight_norm=False,\n",
    "                 go_backwards=False, return_state=False, **kwargs):\n",
    "        super(TCN, self).__init__(**kwargs)\n",
    "        self.return_sequences = return_sequences\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.dilations = dilations\n",
    "        self.nb_stacks = nb_stacks\n",
    "        self.kernel_size = kernel_size\n",
    "        self.nb_filters = nb_filters\n",
    "        self.activation_name = activation\n",
    "        self.padding = padding\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_weight_norm = use_weight_norm\n",
    "        self.go_backwards = go_backwards\n",
    "        self.return_state = return_state\n",
    "\n",
    "        self.residual_blocks = []\n",
    "        for s in range(self.nb_stacks):\n",
    "            for d in self.dilations:\n",
    "                self.residual_blocks.append(ResidualBlock(dilation_rate=d,\n",
    "                                                          nb_filters=self.nb_filters,\n",
    "                                                          kernel_size=self.kernel_size,\n",
    "                                                          padding=self.padding,\n",
    "                                                          activation=self.activation_name,\n",
    "                                                          dropout_rate=self.dropout_rate,\n",
    "                                                          kernel_initializer=self.kernel_initializer,\n",
    "                                                          use_batch_norm=self.use_batch_norm,\n",
    "                                                          use_layer_norm=self.use_layer_norm,\n",
    "                                                          use_weight_norm=self.use_weight_norm))\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = inputs\n",
    "        for block in self.residual_blocks:\n",
    "            x = block(x, training=training)\n",
    "        \n",
    "        if self.return_sequences:\n",
    "            return x\n",
    "        else:\n",
    "            return x[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compiled_tcn(num_feat, num_classes, nb_filters, kernel_size, dilations, nb_stacks, max_len,\n",
    "                 output_len=1, padding='causal', use_skip_connections=False, return_sequences=True,\n",
    "                 regression=False, dropout_rate=0.05, name='tcn', kernel_initializer='he_normal',\n",
    "                 activation='relu', opt='adam', lr=0.002, use_batch_norm=False,\n",
    "                 use_layer_norm=False, use_weight_norm=False):\n",
    "    dilations = adjust_dilations(dilations)\n",
    "    input_layer = Input(shape=(max_len, num_feat))\n",
    "    x = TCN(nb_filters, kernel_size, nb_stacks, dilations, padding, use_skip_connections,\n",
    "            dropout_rate, return_sequences, activation, kernel_initializer, use_batch_norm,\n",
    "            use_layer_norm, use_weight_norm, name=name)(input_layer)\n",
    "\n",
    "    def get_opt():\n",
    "        if opt == 'adam':\n",
    "            return Adam(learning_rate=lr, clipnorm=1.0)\n",
    "        elif opt == 'rmsprop':\n",
    "            return tf.keras.optimizers.RMSprop(learning_rate=lr, clipnorm=1.0)\n",
    "        else:\n",
    "            raise ValueError('Only Adam and RMSProp are available here')\n",
    "\n",
    "    if not regression:\n",
    "        x = Dense(num_classes)(x)\n",
    "        x = Activation('softmax')(x)\n",
    "        output_layer = x\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer=get_opt(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        x = Dense(output_len)(x)\n",
    "        x = Activation('linear')(x)\n",
    "        output_layer = x\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(optimizer=get_opt(), loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tcn_full_summary(model: Model, expand_residual_blocks=True):\n",
    "    if tf.__version__ <= '2.5.0':\n",
    "        layers = model.layers.copy()\n",
    "        model._layers.clear()\n",
    "\n",
    "        for layer in layers:\n",
    "            if isinstance(layer, TCN):\n",
    "                for sub_layer in layer.layers:\n",
    "                    if not isinstance(sub_layer, ResidualBlock):\n",
    "                        model._layers.append(sub_layer)\n",
    "                    else:\n",
    "                        if expand_residual_blocks:\n",
    "                            for sub_sub_layer in sub_layer.layers:\n",
    "                                model._layers.append(sub_sub_layer)\n",
    "                        else:\n",
    "                            model._layers.append(sub_layer)\n",
    "            else:\n",
    "                model._layers.append(layer)\n",
    "\n",
    "        model.summary()\n",
    "        model._layers.clear()\n",
    "        model._layers.extend(layers)\n",
    "    else:\n",
    "        print('WARNING: tcn_full_summary: Compatible with tensorflow 2.5.0 or below.')\n",
    "        print('Use tensorboard instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_model(model, model_name, root_folder=\"saved_models\"):\n",
    "    \"\"\"\n",
    "    Save a given model's architecture as a JSON file and weights as an H5 file.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: Trained model to save.\n",
    "    - model_name: Name of the model (e.g., \"LSTM\", \"RNN\").\n",
    "    - root_folder (default='saved_models'): Name of the root folder where model subfolders will be created.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Define the model-specific directory path\n",
    "    model_dir = os.path.join(root_folder, model_name)\n",
    "\n",
    "    # Ensure the save directory exists\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        print(f\"Created directory {model_dir} for saving the model.\")\n",
    "\n",
    "    # Save the model architecture as a JSON file\n",
    "    model_json_path = os.path.join(model_dir, f\"{model_name}.json\")\n",
    "    with open(model_json_path, \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "    print(f\"Model architecture saved to {model_json_path}\")\n",
    "\n",
    "    # Save the model weights as an H5 file\n",
    "    model_weights_path = os.path.join(model_dir, f\"{model_name}.weights.h5\")\n",
    "    model.save_weights(model_weights_path)\n",
    "    print(f\"Model weights saved to {model_weights_path}\")\n",
    "\n",
    "    print(f\"Saved {model_name} model to {model_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_TCN_model(X_train, Y_train, X_val, Y_val, look_back=10, num_feat=2, nb_filters=64, kernel_size=4, dilations=[1, 2, 4, 8, 16, 32], nb_stacks=1, lr=0.005, dropout_rate=0.5):\n",
    "    model = compiled_tcn(num_feat=num_feat, num_classes=1, nb_filters=nb_filters, kernel_size=kernel_size,\n",
    "                         dilations=dilations, nb_stacks=nb_stacks, max_len=look_back, regression=True,\n",
    "                         dropout_rate=dropout_rate, lr=lr)\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "    history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=32, callbacks=[early_stop, reduce_lr])\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "num_feat = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/16 14:18:09 INFO mlflow.tracking.fluent: Experiment with name 'TF_TCN_Model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MENGDELIN\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3739"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 166ms/step - loss: 4.8274 - val_loss: 0.0458 - learning_rate: 0.0050\n",
      "Epoch 2/100\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0401 - val_loss: 0.0300 - learning_rate: 0.0050\n",
      "Epoch 3/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0299 - val_loss: 0.0137 - learning_rate: 0.0050\n",
      "Epoch 4/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0212 - val_loss: 0.0088 - learning_rate: 0.0050\n",
      "Epoch 5/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0164 - val_loss: 0.0085 - learning_rate: 0.0050\n",
      "Epoch 6/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0173 - val_loss: 0.0084 - learning_rate: 0.0050\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0162 - val_loss: 0.0089 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0181 - val_loss: 0.0073 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0178 - val_loss: 0.0093 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0149 - val_loss: 0.0066 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0145 - val_loss: 0.0076 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0163 - val_loss: 0.0067 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0181 - val_loss: 0.0088 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0163 - val_loss: 0.0074 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0143 - val_loss: 0.0057 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0143 - val_loss: 0.0093 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m6/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0178 - val_loss: 0.0062 - learning_rate: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0161 - val_loss: 0.0084 - learning_rate: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0192"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0187 - val_loss: 0.0069 - learning_rate: 0.0050\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0146 - val_loss: 0.0078 - learning_rate: 0.0050\n",
      "Epoch 21/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0206 - val_loss: 0.0064 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0177 - val_loss: 0.0073 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0199 - val_loss: 0.0068 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0214 - val_loss: 0.0068 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0178 - val_loss: 0.0075 - learning_rate: 1.0000e-03\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/16 14:18:49 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\MENGDE~1\\AppData\\Local\\Temp\\tmp6rbs0d8y\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.16.1', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/05/16 14:18:49 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\MENGDELIN\\anaconda3\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816ms/step\n",
      "Shape of predicted_values: (31, 10)\n",
      "Shape of Y_test: (31,)\n",
      "MSE: 0.0036282774339353005\n",
      "RMSE: 0.06023518435213177\n",
      "MAE: 0.05322828562191889\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"TF_TCN_Model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.tensorflow.autolog()  # Automatically record TensorFlow parameters, indicators and models\n",
    "\n",
    "    # Train TCN model\n",
    "    TCN_model, TCN_history = train_TCN_model(X_train, Y_train, X_val, Y_val, look_back=look_back, num_feat=num_feat)\n",
    "\n",
    "    # Predict test set\n",
    "    predicted_values = TCN_model.predict(X_test)\n",
    "    predicted_values = np.squeeze(predicted_values)\n",
    "\n",
    "    # Check if the shapes match\n",
    "    print(f\"Shape of predicted_values: {predicted_values.shape}\")\n",
    "    print(f\"Shape of Y_test: {Y_test.shape}\")\n",
    "\n",
    "    # Average predicted_values\n",
    "    predicted_values = np.mean(predicted_values, axis=1)\n",
    "\n",
    "    # Visualize predictions vs true values(In testing)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(Y_test, predicted_values, color='blue', alpha=0.5)\n",
    "    plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'k--', lw=3)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Actual vs Predicted Values')\n",
    "    plt.savefig(\"Actual_vs_Predicted_values.png\")\n",
    "    plt.close()\n",
    "\n",
    "     # Log scatter plot to mlflow\n",
    "    mlflow.log_artifact(\"Actual_vs_Predicted_values.png\")\n",
    "\n",
    "    # Plot a comparison between predicted and actual values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(Y_test, label=\"Actual values\", color='blue', alpha=0.5)\n",
    "    plt.plot(predicted_values, label=\"Predicted values of \", color='red', alpha=0.5)\n",
    "    plt.title(\"Predicted_values vs Actual values\")\n",
    "    plt.savefig(\"Comparison_plot.png\")\n",
    "    plt.close() \n",
    "\n",
    "    # Log comparison plot to mlflow\n",
    "    mlflow.log_artifact(\"Comparison_plot.png\")\n",
    "\n",
    "    mse_tcn = mean_squared_error(Y_test, predicted_values)\n",
    "    rmse_tcn = np.sqrt(mse_tcn)\n",
    "    mae_tcn = mean_absolute_error(Y_test, predicted_values)\n",
    "    \n",
    "    # Logging metrics into MLflow\n",
    "    mlflow.log_metric(\"mse_tcn\", mse_tcn)\n",
    "    mlflow.log_metric(\"rmse_tcn\", rmse_tcn)\n",
    "    mlflow.log_metric(\"mae_tcn\", mae_tcn)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"MSE: {mse_tcn}\")\n",
    "    print(f\"RMSE: {rmse_tcn}\")\n",
    "    print(f\"MAE: {mae_tcn}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
